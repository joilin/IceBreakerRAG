import os
from backend.core import run_llm
from backend.ingestion import load_file
import streamlit as st
from streamlit_chat import message

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []
if "vector_store" not in st.session_state:
    st.session_state.vector_store = None
# if "prompt" not in st.session_state:
#     st.session_state.prompt = ""

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
with st.sidebar:
    st.title("âš™ï¸ è¨­å®š")
    file_path = st.text_input("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å…¥åŠ›:",key="filepath_input")

    if st.button("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’åŸ‹ã‚è¾¼ã¿",key="file_load_button"):
        if os.path.exists(file_path):
            load_file(file_path)
            st.write("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ")
        else:
            st.error("ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

# ãƒ¡ã‚¤ãƒ³ç”»é¢
st.title("ğŸ’¬ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")
st.caption("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã«åŸ‹ã‚è¾¼ã‚“ã§è³ªå•ã§ãã¾ã™")

# # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
# def clear_text():
#     # å…¥åŠ›å†…å®¹ã‚’ã‚¯ãƒªã‚¢
#     st.session_state.prompt = ""

prompt = st.text_input("Prompt",key="prompt_input",placeholder="Enter your prompt here...")



if (
    "chat_answer_history" not in st.session_state
    and "user_prompt_history" not in st.session_state
    and "chat_history"  not in st.session_state
):
    st.session_state["chat_answer_history"] = []
    st.session_state["user_prompt_history"] = []
    st.session_state["chat_history"] = []

if prompt:
    with st.spinner("Generating response..."):
        generated_response = run_llm(
            query=prompt,chat_history=st.session_state["chat_history"]
        )

        formatted_response = f"{generated_response['answer']}"

        st.session_state["chat_answer_history"].append(prompt)
        st.session_state["user_prompt_history"].append(formatted_response)
        st.session_state["chat_history"].append(("human",prompt))
        st.session_state["chat_history"].append(("ai",generated_response['answer']))

        # # å…¥åŠ›å†…å®¹ã‚’ã‚¯ãƒªã‚¢
        # clear_text()

if st.session_state["chat_answer_history"]:
    # for generated_response,user_query in zip(st.session_state["chat_answer_history"],st.session_state["user_prompt_history"]):
    #     message(user_query,is_user=True,key="user_message")
    #     message(generated_response,key="llm_message")

    # é€†é †ã§ãƒ«ãƒ¼ãƒ—å‡¦ç†
    for i, (generated_response, user_query) in enumerate(reversed(list(zip(
            st.session_state["chat_answer_history"],
            st.session_state["user_prompt_history"]
    )))):
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’é€†é †ã«åˆã‚ã›ã¦èª¿æ•´
        original_index = len(st.session_state["chat_answer_history"]) - i - 1
        message(generated_response, key=f"bot_{original_index}")
        message(user_query, is_user=True, key=f"user_{original_index}")


